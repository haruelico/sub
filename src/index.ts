import { app, BrowserWindow } from 'electron';
// import * as recorder from 'node-record-lpcm16'
// const recorder = require("node-record-lpcm16")
import { Sox } from "./lib/sox"
import speech from "@google-cloud/speech"

// This allows TypeScript to pick up the magic constant that's auto-generated by Forge's Webpack
// plugin that tells the Electron app where to look for the Webpack-bundled app code (depending on
// whether you're running in development or production).
declare const MAIN_WINDOW_WEBPACK_ENTRY: string;
declare const MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY: string;
const sox = new Sox()
const speechClient = new speech.SpeechClient()
const recognizeStream = speechClient.streamingRecognize({
  config: {
    encoding: "LINEAR16",
    sampleRateHertz: 16000,
    languageCode: "ja-JP"
  },
  interimResults: true
}).on("error", console.error).on("data", data => {
  console.log(
    data.results[0] && data.results[0].alternatives[0] ?
      `Transcription: ${data.results[0].alternatives[0].transcript}`
      : '\n\nReached transcription time limit, press Ctrl+C\n'
  )
})
sox.start().stream().on('error', console.error).pipe(recognizeStream)

// Handle creating/removing shortcuts on Windows when installing/uninstalling.
if (require('electron-squirrel-startup')) { // eslint-disable-line global-require
  app.quit();
}

const createWindow = (): BrowserWindow => {
  // Create the browser window.
  const mainWindow = new BrowserWindow({
    height: 600,
    width: 800,
    webPreferences: {
      contextIsolation: true,
      preload: MAIN_WINDOW_PRELOAD_WEBPACK_ENTRY
    }
  });

  // and load the index.html of the app.
  mainWindow.loadURL(MAIN_WINDOW_WEBPACK_ENTRY);

  // Open the DevTools.
  mainWindow.webContents.openDevTools();

  return mainWindow
};

// This method will be called when Electron has finished
// initialization and is ready to create browser windows.
// Some APIs can only be used after this event occurs.
app.on('ready', () => {
  const window = createWindow()

  const recognizeStream = speechClient.streamingRecognize({
    config: {
      encoding: "LINEAR16",
      sampleRateHertz: 16000,
      languageCode: "ja-JP"
    },
    interimResults: true
  }).on("error", console.error).on("data", data => {
    let text = data.results[0] && data.results[0].alternatives[0] ? data.results[0].alternatives[0].transcript: 'none'

    console.log(text)
    window.webContents.send("speech-to-text", text)
    console.log(
      data.results[0] && data.results[0].alternatives[0] ?
        `Transcription: ${data.results[0].alternatives[0].transcript}`
        : '\n\nReached transcription time limit, press Ctrl+C\n'
    )
  })
  sox.start().stream().on('error', console.error).pipe(recognizeStream)
});

// Quit when all windows are closed, except on macOS. There, it's common
// for applications and their menu bar to stay active until the user quits
// explicitly with Cmd + Q.
app.on('window-all-closed', () => {
  if (process.platform !== 'darwin') {
    sox.stop()
    app.quit();
  }
});

app.on('activate', () => {
  // On OS X it's common to re-create a window in the app when the
  // dock icon is clicked and there are no other windows open.
  if (BrowserWindow.getAllWindows().length === 0) {
    createWindow();
  }
});

// In this file you can include the rest of your app's specific main process
// code. You can also put them in separate files and import them here.
